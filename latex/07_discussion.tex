\subsubsection{Research Questions}

\subsubsection{Limitations}
% - Though we implemented extending window, computing resources limitataitons does not allow me to do 2 decades backtest. Ideally, this analysis should be doen with a proper extending window: train for X numbers of days lookback-> test day after. Then extend window. THen repeat for 20 years. THis paper did do the extending window continous retraining with extending window frame of 1 training year for 20 years. However it is reported as out-of-bag score only. With only 1 year to test out the extending window, it is not ideal. However it got a proxy what the actual result would be.

% - Constraints of ARL: This rule based method is based on manual threshold. Something of recent research, like RuleFit would be better. We are doing RF+ARL -> signals. However Rulefit does not need to be combined with anything else. It could create rules directly as a feature of the algo. These re actual if-then rules, such as "if market return >alpha and turn<= beta and news_sent> gamma then excess_return = 10\%".

% - Cannot statisically proof that either C4F or FF5 is better. But does not seem to entirely matter to non parametric models as we could include both (for forecasting purposes) SHAP, PDP and Feature Importance are only informative, not statisical proofs.
Despite implementing an expanding-window scheme, our back-test remains confined to a single year of walk-forward evaluation due to computational constraints. Ideally, we would train on an initial lookback of $X$ trading days, test on the subsequent day, then extend the training window and repeat this process continuously over a 20-year period. While this paper reports out of bag performance for a one-year training frame across two decades, the absence of a full dataset rolling back test in our study limits the robustness of our conclusions. Our one year proxy, however, suggests that the expanding window approach would likely produce comparable results over a longer time frame.

%TODO RFI: Despite these advantages, two important caveats must be borne in mind. First, local validity is limited: outside the neighbourhood surrounding the point \((x_{1},\dots,x_{p})\), the relationship between factors and returns may differ substantially, so pseudo‐betas should not be extrapolated beyond their local region without caution. Second, the \textbf{independence assumption} underlying the raw elasticities treats factors as if they were orthogonal when computing \(\varepsilon_{k}=\hat y / x_{k}\), which may misattribute explanatory power in the presence of strong interactions. To mitigate this, researchers can group interacting predictors prior to calculating pseudo‐betas or report complementary Shapley‐value attributions to validate and cross‐check the results.  

The ARL relies on manually selected support and confidence thresholds, which may render the extracted “if-then” sector-rotation rules sensitive to arbitrary parameter choices. Recent advances—such as the \texttt{RuleFit} algorithm, which generate sparse, additive rule ensembles directly from the data without the need for external rule mining and threshold tuning. By integrating rule extraction into the learner itself, RuleFit produces concise, interpretable rules (e.g.\ \emph{if} market return $>$ $\alpha$ \emph{and} turnover $\le \beta$ \emph{and} sentiment $>$ $\gamma$, \emph{then} excess return $=10\%$) while avoiding the two-step RF+ARL pipeline.

Finally, we cannot statistically demonstrate that the C4F or FF5 formulations are superior within a non-parametric forecasting framework. In practice, RF models can accommodate both factor sets simultaneously and simply don't split on redudant predictors. Moreover, interpretability tools—feature importance, SHAP values, and PDP—offer descriptive insights into factor contributions but do not constitute formal hypothesis tests. Future work should incorporate inferential procedures (e.g.\ testing differences in out-of-sample $R^2$ or using bootstrap confidence intervals for SHAP contributions) to underpin the economic relevance of each factor choice.

\subsubsection{How investors and asset managers can use the findings of this paper}
% - ideal workflow: gather past data -> plug in -> auto feature engineers_> pipeline (rf -> arl-> rules) -> weighting on tomorrows sector. Tomorrow comes, automatcially include today in traning window, adjust for todays excess returns -> forecast tomorrow -> weight tomorrow..
% - When an actual trade is not as expected -> can go back and see exactly which factor caused the trade to be not as expected with feature importance, shap, pdp
% - With incorporation of sentiment, liquidity risks, can think about other macroeconomic factoers that are less niche, since the two most promonient factors are taken into account. Help financial professional make better decisions that are always explainable at every single step of the trading route
For asset managers, this is the proposed pipeline: automated data ingestion $\rightarrow$ feature engineering $\rightarrow$ RF forecasting $\rightarrow$ rule extraction. This pipeline delivers a daily sector-weight vector whose rationale can be traced factor-by-factor. When live trades deviate from expectations, global and local attribution via feature importance, SHAP, or partial dependence immediately isolates which of the traditional FF factors ($SMB$, $HML$, $MOM$, $RMW$, $CMA$), the liquidity variables, or the sentiment index drove the surprise deviation. Because liquidity risk and sentiment already proxy two of the most pervasive macro drivers, practitioners can next experiment with complementary state variables (e.g.\ term-structure slope, credit spreads) without materially inflating model complexity.


% \noindent\textbf{Recommended refinements and theoretical checks}
% \begin{itemize}
% \item \emph{Statistical testing}: report out-of-sample $\Delta R^{2}$ p-values and Diebold-Mariano statistics to demonstrate that RF-based enhancements are materially better than OLS and not materially worse than vanilla RF.
% \item \emph{Factor choice}: clarify why $C4F$ vs.\ $FF5$ matters once non-parametric learners are used; consider including both sets of factors and letting the algorithm down-weight redundant ones.
% \item \emph{Back-test design}: extend the expanding-window evaluation to the full 1990-2018 span; document walk-forward hyper-parameter tuning to avoid look-ahead bias.
% \item \emph{Interpretability caveat}: remind readers that SHAP and permutation scores are \emph{not} formal statistical betas; they measure marginal predictive contribution, not economic elasticity.
% \item \emph{Liquidity–sentiment theory}: verify that liquidity betas indeed earn a premium during market stress (e.g.\ 2008, 2020) and that sentiment loads interact with the size factor, as implied by \citeA{baker_wurgler_2007}.
% \end{itemize}