%%%OUTLINE:%%%%

- liquidity risk factors construction
- sentiment construction
- fama and carhart models/factors 
- random forest
- Rule based model
- sector rotation strategy: Association rule learning

This chapter outlines the methodological approach adopted to measure liquidity risk and investors' sentiment, along with their rationale. These factors are integrated into an enhanced asset pricing framework based on the FF5 and C4F. Subsequently, the implementation of the Random Forest (RF) algorithm is detailed. Next, the rule-based model will be extracted from the RF for comparison and application to the Association Rule Learning Sector Rotation Strategy.

\subsection{Liquidity Risk factor}
%%%%% ACTUAL%%%%%%%%%%%
The construction of liquidity factors closely align with the methodology outlined by \citeA{gu_2020}. The authors include multiple liquidity related variables, including turnover and turnover volatility (\texttt{turn}, \texttt{SDturn}), log market equity (\texttt{mvel1}), dollar volume (\texttt{dolvol}), Amihud illiquidity (\texttt{ILLQ}), number of zero trading days (\texttt{zerotrade}), and bid-ask spread (\texttt{baspread}). \citeA{amihud_2002} defined their illiquidity measure \texttt{ILLQ} as the "average ratio of the daily absolute return to the(dollar)trading volume on that day. This index captures waves of excessive optimism or pessimism in the market.  The calculation for Amihud illiquidity is as follows:

\begin{equation}
    \label{eq:amihud}
    \text{ILLIQ}_{i,y} = \frac{1}{D_i^y} \sum_{d=1}^{D_i^y} \frac{|R_{i,d}|}{VOL_{i,d}}
\end{equation}
    
with $R_{i,d}$ being the return on stock $i$ on day $d$. $VOL_{i,d}$ being trading volume (in dollars) for stock $i$ on day $d$ and $D_i^{y}$ being the number of days for which data is available for stock $i$ in year $y$. \citeA{amihud_2002} suggested that this measure be multipled with the ratio of $10^6$, as the ratio would be tiny. Each stock-level liquidity characteristic is cross-sectionally ranked period-by-period, then mapped into a standardized interval ranging from -1 to 1 \cite{gu_2020}. 

%(is batch normalization needed?)

%Add a part that says unlike the literature on this topic, no portfolio sorting is needed.

\subsection{Sentiment}
%% OUTLINE: wurgler -> antoniu -> XU enhanced
\citeA{wurgler_2006} constructed a sentiment index (BW index hereafter) by capturing the principal components within six proxies: closed-end fund discount (\texttt{CEFD}), NYSE share turnover (\texttt{TURN}), the number and average first-day returns of IPOs (\texttt{NIPO, RIPO} respectively), equity share in new issues (\texttt{S}) and dividend premium (\texttt{P}). \footnote{However, by March 2016, the NYSE share turnover proxy has been dropped in the database due to "the explosion of institutional high-frequency trading and the migration of trading to a variety of venues" \cite{ung_2023}}%can definitely add more after the proposal here, from the paper

The sentiment is calculated as follows:
\begin{equation}
    \label{eq:sentiment}
    \begin{split}
    \text{SENTIMENT}_t = -0.241\,\text{CEFD}_t + 0.242\,\text{TURN}_{t-1} \\ + 0.253\,\text{NIPO}_t 
    + 0.257\,\text{RIPO}_{t-1} \\ + 0.112\,S_t - 0.283\,P^{D-ND}_{t-1} , 
    \end{split}
\end{equation}

where each proxy has been standardized. $\text{D}-\text{ND}$ is the difference between dividend payers and non-dividend payers. Principal Component Analysis(PCA) reveals the hidden common factor from this group of factors by transforming the data into principal components (PCs) that would capture as much variance in the data as possible. PC1 should capture the maximum variation from the sentiment proxies, thereby serving as an aggregate measure of investor sentiment. Since both market sentiment and the business cycle can drive common variation in financial data, the PCA will treat both as sources of variance without distinguishing whether that variance comes from changes in investor sentiment or broader macroeconomic factors. A second orthogonalized index is formed by regressing each of the proxy with independent variables that explains the business cycle. The residuals of this regression will be the 'pure" sentiment, which is the variation that the macroeconomic factors fail to explain. The following is the orthogonalized index, with $\perp$ labelling the removal of business cycle. 

\begin{equation} %BEQ
    \label{eq:sentiment_orth}
    \begin{split}
    \text{SENTIMENT}^{\perp}_t = &-0.198\,\text{CEFD}^{\perp}_t + 0.225\,\text{TURN}^{\perp}_{t-1} \\
    &+ 0.234\,\text{NIPO}^{\perp}_t + 0.263\,\text{RIPO}^{\perp}_{t-1} \\
    &+ 0.211\,S^{\perp}_t - 0.243\,\text{P}^{\text{D} - \text{ND},\perp}_{t-1}
    \end{split}
\end{equation}

However, \citeA{ung_2023} pointed out several problems with the BW index. First, though it has robust predictive perfomance on a cross- sectional level, it is weak for aggregate market retuerns in time series regressions - even \citeA{wurgler_2007} pointed this out themselves in the paper. Second, the BW index assumes that the contributions of each sentiment proxy to the aggregate index are fixed over time. Finally, the index has `look ahead bias': PCA uses the whole sample, and forecasts at time $t$ should not rely on data that would only become available after $t$. Therefore, \citeA{ung_2023} constructed an enhanced index to address these problems. The time-varying BW sentiment index ($S^{TV}$ hereafter) is constructed on a three years rolling window basis to use the most up-to-date information at each $t$, and is built upon \cref{eq:sentiment_orth}. This rolling window allows the model to adjust to structural breaks in the market without distorting the sentiment index. Furthermore, adjustments to the sign of the RICO proxy display a negative initial loading. This paper will use \citeA{ung_2023} $S^{TV}$ index to measure investors' sentiment.


\subsection{Factor models}
%%%%%%ACTUAL%%%%%%
This thesis will employ two CAPM variants: the C4F of \citeA{cahart_1997} and FF5 of \citeA{ff5_2015}. The following are their respective formulas:

\begin{equation}
    \label{eq:c4f}
    \begin{split}
        R_{i,t} - R_{f,t} &= \alpha_i + \beta_{MKT} (R_{MKT,t} - R_{f,t}) \\
        &\quad + \beta_{SMB} \cdot SMB_t + \beta_{HML} \cdot HML_t \\
        &\quad + \beta_{MOM} \cdot MOM_t + \epsilon_{i,t}
    \end{split}
\end{equation}

\begin{equation}
    \label{eq:ff5}
    \begin{split}
        R_{i,t} - R_{f,t} &= \alpha_i + \beta_{MKT} (R_{MKT,t} - R_{f,t}) \\
        &\quad + \beta_{SMB} \cdot SMB_t + \beta_{HML} \cdot HML_t \\
        &\quad + \beta_{RMW} \cdot RMW_t + \beta_{CMA} \cdot CMA_t + \epsilon_{i,t}
    \end{split}
\end{equation}

where \cref{eq:c4f} is the C4F and \cref{eq:ff5} is the FF5. $R_{i,t}$ is the return on security and $R_{f,t}$ is the risk-free return; which makes $R_{i,t} - R_{f,t}$ is the excess return on a security. $SMB$ (small minus big) is the size factor, capturing the excess returns of small-cap stocks over large-cap stocks, reflecting how higher volatility and growth potential could cause smaller firms to yield higher average returns. $HML$ (high minus low), or the value factor, accounts for the premium earned by stocks with high book-to-market ratios, often associated with underperforming firms that carry higher risk and, consequently, higher expected returns \cite{ff3_1993}. $MOM$ is the one year momentum factor \footnote{In literature, researchers can refer to this factor as PR1YR, UMD (ups minus downs), or WML (winners minus losers.)} \cite{cahart_1997}. In response to \citeA{titman_2004} and \citeA{novymarx_2013} criticisms, two additional factors were added in to the FF3 model \cite{ff5_2015}. $RMW$ (robust minus weak) is the profitability factor, which derives from the empirical observation that firms with higher operating profitability tend to earn higher average returns. $CMA$ (conservative minus aggressive) is the investment factor, which captures the tendency of firms to aggressively invest in new assets, expecting higher returns in the long run. Investors may overpay for such firms due to optimism, which results in lower subsequent returns \cite{titman_2004}.

The empirical analysis will begin by establishing a baseline for each asset pricing variant using time series regressions, employing Ordinary Least Squares (OLS) as outlined by \citeA{simonian_2019}. \cref{eq:c4f} and \cref{eq:ff5}, the two baseline variants will be referred to as C4F-B and FF5-B hereafter. Subsequently, liquidity risk and sentiment indicators will be integrated into these variants, thereby forming an enhanced baseline. The following are the enhanced baseline models:

\begin{equation}
    \label{eq:c4f_expanded}
    \begin{split}
    R_{i,t} - R_{f,t} &= \alpha_i + \beta_{MKT} (R_{MKT,t} - R_{f,t}) \\
    &\quad + \beta_{SMB} \cdot SMB_t + \beta_{HML} \cdot HML_t \\
    &\quad + \beta_{MOM} \cdot MOM_t \\
    &\quad + \beta_{turn} \cdot TURN_{i,t} + \beta_{SDturn} \cdot SDTURN_{i,t} \\
    &\quad + \beta_{mvel1} \cdot MVEL1_{i,t} + \beta_{DOLVOL} \cdot DOLVOL{i,t} \\
    &\quad + \beta_{ILLQ} \cdot ILLQ_{i,t} + \beta{zerotrade} \cdot ZEROTRADE_{i,t} \\
    &\quad + \beta_{baspread} \cdot BASPREAD_{i,t} + \epsilon{i,t}
    \end{split}
\end{equation}

\begin{equation}
    \label{eq:ff5_expanded}
    \begin{split}
    R_{i,t} - R_{f,t} &= \alpha_i + \beta_{MKT} (R_{MKT,t} - R_{f,t}) \\
    &\quad + \beta_{SMB} \cdot SMB_t + \beta_{HML} \cdot HML_t \\
    &\quad + \beta_{RMW} \cdot RMW_t + \beta_{CMA} \cdot CMA_t\\
    &\quad + \beta_{turn} \cdot TURN_{i,t} + \beta_{SDturn} \cdot SDTURN_{i,t} \\
    &\quad + \beta_{mvel1} \cdot MVEL1_{i,t} + \beta_{DOLVOL} \cdot DOLVOL{i,t} \\
    &\quad + \beta_{ILLQ} \cdot ILLQ_{i,t} + \beta{zerotrade} \cdot ZEROTRADE_{i,t} \\
    &\quad + \beta_{baspread} \cdot BASPREAD_{i,t} + \epsilon{i,t}
    \end{split}
\end{equation}

where \cref{eq:c4f_expanded} is the enhanced C4F baseline (C4F-BE) and \cref{eq:ff5_expanded} the enhanced FF5 enhanced baseline (FF5-BE). %explain why no portfolio sortings here? 


\subsection{Random Forest}

%%%%%%%%OUTLINE%%%%%%%%%%
%Factor models are generally linear. Which kinds of regression are they usally used with (fama macbeth)? 


%%%%%%%%%%ACTUAL%%%%%%%%%%%%%%%
The C4F-B, C4F-BE, FF5-B and FF5-BE, since based on OLS, are linear in nature. These models are favored by finance practitioners because they produce interpretable results. The main results that the practitioners look for is the sensitivities of the factor within the models, or the beta coefficients within the OLS. However, the method is constraint to several assumptions. The features and the target variables of this method are assummed to be linear and the features themselves are not multicollinear. Furthermore, homoskedactiy is assumed, where the residuals have constant variance at every level of the features. The residuals should also be independent.

%maybe motivate more why tree based methods.
ML models offer a more robust framework, especially Random Forest (RF). Non-linear relationships can be captured and multicollinearity could be dealt with. Furthermore, unlike OLS, RF models are estimated without the inversion of the covariance matrix. Parametric assumptions are not required, therefore heteroskedacity and non-independence of errors are accepted. The following RF implementation follows \citeA{simonian_2019}. In the RF model, each factor in \cref{eq:c4f,eq:c4f_expanded,eq:ff5,eq:ff5_expanded} can be represented as a feature to predict the excess return of the security. The baseline equivalent for the RF are named, respectively C4F-RF, C4F-RFE, FF5-RF, FF5-RFE. Stock returns forecasts are then aggregated by sector, which will then be divided into 10th, 25th, 50th, 75th, and 90th percentile. According to \citeA{simonian_2019}, this divide often show assymetric relationships within a set of observations. For example, certain features are more prevalent with low return portfolios than high return portfolios.

A downside of RF (and most other ML models) is their "black-box" nature, where their inner workings are unintuitive, which makes it unattractive to many investment professionals. RF captures non-geometric relationships between factors, therefore it is not analogous to the interpretation of common methods in the financial field (OLS, PCA). However, there are still multiple ways that can give investors insights into the RF black-box. The most common method utilized is the Relative Feature Importance (RFI hereafter), which weighs all of the factors within the RF according to their predictive robustness. \citeA{simonian_2019} attemted to generate what is similar to "betas" in traditional asset pricing models from RFI. An accepted understanding of "betas" in linear models is the elasticity of one variable to another, therefore a RFI-weighted elasticity, or "psuedo-beta" is constructed:

\begin{equation}
    \label{eq:psuedo}
    \frac{\text{Target Variable value}}{\text{{Feature value}}}* \text{RFI}
\end{equation}

By utilizing this method, the interpretation of the RF models could be communicated with investment professionals who are more familiar with OLS betas or PCA loadings.

\subsection{Rule-based models}
There are statistical methods that only sacrifice a small amount of accuracy, but its inner workings are translated into "if-then" statements that could be communicated to investment managers. Rule-based models turns the “black box” RF into a transparent collection of "if-then" statements \cite{benard_2021}. Each rule summarizes a path of decisions about factor values. In this particular context, a rule could be “If $\texttt{ILLQ}$ exceeds a certain threshold and \texttt{HML} remains below a specific level, then $\texttt{Expected Excess Return} = x$.”. Such structures mirror how a practitioner might articulate investment strategies.

This intepretable rule based model is outlined in \citeA{benard_2021}, which introduces \textbf{S}table and \textbf{I}nterpretable \textbf{RU}le \textbf{S}et (SIRUS) for regression, based on RF. After the Random Forest is built, every possible condition-based rule that can come out of the trees is examined. Because each tree splits the data in different ways, some rules will appear in multiple trees, whereas others might appear only once. Rules that show up more frequently across the entire forest are considered more reliable because their conditions hold under various random draws and data subsets. Next, we choose a cutoff point to decide when a rule appears “often enough” to be considered important. If a rule meets or exceeds this cutoff in how frequently it shows up in the RF, we keep it; if not, we discard it. After keeping only the important rules, we bring them together into a single model. Essentially, each rule can give a “low” or “high” prediction, depending on whether its condition applies or not. We then assign a weight to each rule, so that the final prediction is just the sum of these weighted rules plus an overall baseline value. Because we only keep a handful of the most frequent rules, the end result is both more concise and easier to understand, resembling a clear list of if-then statements with associated weights. The best performing RF model out of C4F-RF, C4F-RFE, FF5-RF and FF5-RFE in predicting returns will be eligible for SIRUS rule extraction. This model will be referred to as RF-SIRUS hereafter.
 

\subsection{Sector rotation strategy}
The best RF variant and its SIRUS extraction will be adapted to a practical trading application, providing investors and practitioners in the field a tool that provide insights and guide them on investment decisions. After the RF and SIRUS forecasts, the excess returns of each sector will be aggregated by sector for the month ahead. With a sector rotation strategy, the sector that is held in the portfolio is the one that signals outperformance on the market. The sector rotation strategy implemented in this paper closely follows \citeA{simonian_2019} methods, using Association Rule Learning (ARL). The signals utilized by the authors are the one month ahead predicted returns and ratio of shorter-term to longer-term realized volatility (24-month vs. 36-month), which is calculated as follows:

\begin{equation}
    \label{eq:vol_ratio}
    VR_t = \text{Volatility ratio at time } t = \frac{\text{Volatility}(t-24, t)}{\text{Volatility}(t-36, t)}
\end{equation}
    

Generally, ARL searches through large observations to find association rules. It is a rolling-window learning approach, meaning it updates on new data that comes in. Instead of using a fixed model trained once on historical data, it re-estimates the relationships every 18 months, which is called a "look-back" window.  The idea is to discover whether certain thresholds of “predicted return” and “volatility ratio” tend to coincide with above-average returns in the following month. The sector will be owned in the portfolio if the following conditions are sastisfied \footnote{A more formal description will be provided in the Methods section of the thesis}:

\begin{equation}
    \label{eq:arl}
    (\text{Volatility ratio} < 1) \land (\text{RF-predicted return} > \alpha) \implies (\text{Sector return} > \beta)
\end{equation}
    


%iterative add factor de xem la feature importance co doi ko 